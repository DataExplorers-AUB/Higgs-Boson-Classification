{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LozuXJDWxrj"
      },
      "source": [
        "# **Higgs boson project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34Wpd8IXew2"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4EB_p5oATAq"
      },
      "outputs": [],
      "source": [
        "import google.colab as gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hSvKQ_jC2x3",
        "outputId": "29130e22-9f39-4347-9047-dee98ee3f8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Read the data from google drive\n",
        "gc.drive.mount(\"/content/drive\", force_remount=True)\n",
        "frame_names = [\"Higgs boson\",\"lepton pT\", \"lepton eta\", \"lepton phi\", \"missing energy magnitude\", \"missing energy phi\", \"jet 1 pt\",\n",
        "               \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\", \"jet 2 pt\", \"jet 2 eta\", \"jet 2 phi\", \"jet 2 b-tag\", \"jet 3 pt\",\n",
        "               \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\", \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\", \"m jj\",\n",
        "               \"m jjj\", \"m lv\", \"m jlv\", \"m bb\", \"m wbb\", \"m wwbb\"]\n",
        "\n",
        "def read_data(file_path):\n",
        "    data = pd.read_csv(file_path, names=frame_names, low_memory=False)\n",
        "    data[\"Higgs boson\"] = data[\"Higgs boson\"].astype(\"category\").cat.codes\n",
        "    \n",
        "    data = convert_invalid_types(data)\n",
        "\n",
        "    # Drop rows with missing values\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "def convert_invalid_types(data):\n",
        "    object_cols = data.select_dtypes(include=[\"object\"])\n",
        "    mixed_type_cols = object_cols.columns[object_cols.apply(pd.Series.nunique) > 1]\n",
        "    for col in mixed_type_cols:\n",
        "        data[col] = pd.to_numeric(data[col].str.replace('\"',''), errors=\"coerce\")\n",
        "    return data\n",
        "\n",
        "data = read_data(\"/content/drive/My Drive/Higgs_Boson_Project/data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAJog-WzX8rY"
      },
      "source": [
        "### Show the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more data visualization, check the python files"
      ],
      "metadata": {
        "id": "JaLGD2sY9hMd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "DtO1W8kAXj7H",
        "outputId": "c3fe9b40-f264-496d-e6ad-cc7e7f8e746b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (599997, 29)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Higgs boson      lepton pT     lepton eta     lepton phi  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean        0.529284       0.992485      -0.000115       0.000163   \n",
              "std         0.499142       0.565045       1.007857       1.005479   \n",
              "min         0.000000       0.275000      -2.430000      -1.740000   \n",
              "25%         0.000000       0.591000      -0.737000      -0.870000   \n",
              "50%         1.000000       0.854000      -0.001030       0.002640   \n",
              "75%         1.000000       1.240000       0.738000       0.870000   \n",
              "max         1.000000       8.710000       2.430000       1.740000   \n",
              "\n",
              "       missing energy magnitude  missing energy phi       jet 1 pt  \\\n",
              "count             599997.000000       599997.000000  599997.000000   \n",
              "mean                   0.998020           -0.001152       0.990147   \n",
              "std                    0.599283            1.006755       0.474626   \n",
              "min                    0.000626           -1.740000       0.139000   \n",
              "25%                    0.577000           -0.873000       0.679000   \n",
              "50%                    0.891000           -0.001910       0.894000   \n",
              "75%                    1.290000            0.872000       1.170000   \n",
              "max                    9.900000            1.740000       8.380000   \n",
              "\n",
              "           jet 1 eta      jet 1 phi    jet 1 b-tag       jet 2 pt  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean       -0.002195       0.000513       1.000378       0.992595   \n",
              "std         1.010297       1.006594       1.026462       0.500731   \n",
              "min        -2.970000      -1.740000       0.000000       0.189000   \n",
              "25%        -0.689000      -0.868000       0.000000       0.656000   \n",
              "50%        -0.003000      -0.001050       1.090000       0.890000   \n",
              "75%         0.685000       0.870000       2.170000       1.200000   \n",
              "max         2.970000       1.740000       2.170000      11.600000   \n",
              "\n",
              "           jet 2 eta      jet 2 phi    jet 2 b-tag       jet 3 pt  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean        0.001639       0.000405       0.997929       0.992338   \n",
              "std         1.008571       1.006940       1.046790       0.487112   \n",
              "min        -2.910000      -1.740000       0.000000       0.264000   \n",
              "25%        -0.693000      -0.871000       0.000000       0.651000   \n",
              "50%         0.001030       0.000454       0.000000       0.898000   \n",
              "75%         0.697000       0.872000       2.210000       1.220000   \n",
              "max         2.910000       1.740000       2.210000       8.510000   \n",
              "\n",
              "           jet 3 eta      jet 3 phi    jet 3 b-tag       jet 4 pt  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean        0.001851       0.000928       1.001304       0.986216   \n",
              "std         1.008364       1.005883       1.195057       0.505672   \n",
              "min        -2.730000      -1.740000       0.000000       0.365000   \n",
              "25%        -0.697000      -0.870000       0.000000       0.618000   \n",
              "50%         0.001990      -0.001310       0.000000       0.868000   \n",
              "75%         0.703000       0.873000       2.550000       1.220000   \n",
              "max         2.730000       1.740000       2.550000      11.600000   \n",
              "\n",
              "           jet 4 eta      jet 4 phi    jet 4 b-tag           m jj  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean       -0.000309      -0.002131       0.996425       1.034049   \n",
              "std         1.008151       1.005563       1.397913       0.669433   \n",
              "min        -2.500000      -1.740000       0.000000       0.107000   \n",
              "25%        -0.715000      -0.872000       0.000000       0.791000   \n",
              "50%        -0.000461      -0.005810       0.000000       0.895000   \n",
              "75%         0.715000       0.868000       3.100000       1.020000   \n",
              "max         2.500000       1.740000       3.100000      22.300000   \n",
              "\n",
              "               m jjj           m lv          m jlv           m bb  \\\n",
              "count  599997.000000  599997.000000  599997.000000  599997.000000   \n",
              "mean        1.024419       1.050636       1.010130       0.973343   \n",
              "std         0.378087       0.164444       0.398453       0.524886   \n",
              "min         0.245000       0.092200       0.157000       0.048100   \n",
              "25%         0.846000       0.986000       0.768000       0.674000   \n",
              "50%         0.950000       0.990000       0.917000       0.873000   \n",
              "75%         1.080000       1.020000       1.140000       1.140000   \n",
              "max        11.600000       5.920000      10.500000      13.700000   \n",
              "\n",
              "               m wbb         m wwbb  \n",
              "count  599997.000000  599997.000000  \n",
              "mean        1.033156       0.959836  \n",
              "std         0.364497       0.313074  \n",
              "min         0.303000       0.351000  \n",
              "25%         0.819000       0.770000  \n",
              "50%         0.947000       0.872000  \n",
              "75%         1.140000       1.060000  \n",
              "max         8.430000       6.260000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-284ba932-f7a7-4058-a734-37e5bb57911d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Higgs boson</th>\n",
              "      <th>lepton pT</th>\n",
              "      <th>lepton eta</th>\n",
              "      <th>lepton phi</th>\n",
              "      <th>missing energy magnitude</th>\n",
              "      <th>missing energy phi</th>\n",
              "      <th>jet 1 pt</th>\n",
              "      <th>jet 1 eta</th>\n",
              "      <th>jet 1 phi</th>\n",
              "      <th>jet 1 b-tag</th>\n",
              "      <th>jet 2 pt</th>\n",
              "      <th>jet 2 eta</th>\n",
              "      <th>jet 2 phi</th>\n",
              "      <th>jet 2 b-tag</th>\n",
              "      <th>jet 3 pt</th>\n",
              "      <th>jet 3 eta</th>\n",
              "      <th>jet 3 phi</th>\n",
              "      <th>jet 3 b-tag</th>\n",
              "      <th>jet 4 pt</th>\n",
              "      <th>jet 4 eta</th>\n",
              "      <th>jet 4 phi</th>\n",
              "      <th>jet 4 b-tag</th>\n",
              "      <th>m jj</th>\n",
              "      <th>m jjj</th>\n",
              "      <th>m lv</th>\n",
              "      <th>m jlv</th>\n",
              "      <th>m bb</th>\n",
              "      <th>m wbb</th>\n",
              "      <th>m wwbb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "      <td>599997.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.529284</td>\n",
              "      <td>0.992485</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.998020</td>\n",
              "      <td>-0.001152</td>\n",
              "      <td>0.990147</td>\n",
              "      <td>-0.002195</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>1.000378</td>\n",
              "      <td>0.992595</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.997929</td>\n",
              "      <td>0.992338</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>1.001304</td>\n",
              "      <td>0.986216</td>\n",
              "      <td>-0.000309</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>0.996425</td>\n",
              "      <td>1.034049</td>\n",
              "      <td>1.024419</td>\n",
              "      <td>1.050636</td>\n",
              "      <td>1.010130</td>\n",
              "      <td>0.973343</td>\n",
              "      <td>1.033156</td>\n",
              "      <td>0.959836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.499142</td>\n",
              "      <td>0.565045</td>\n",
              "      <td>1.007857</td>\n",
              "      <td>1.005479</td>\n",
              "      <td>0.599283</td>\n",
              "      <td>1.006755</td>\n",
              "      <td>0.474626</td>\n",
              "      <td>1.010297</td>\n",
              "      <td>1.006594</td>\n",
              "      <td>1.026462</td>\n",
              "      <td>0.500731</td>\n",
              "      <td>1.008571</td>\n",
              "      <td>1.006940</td>\n",
              "      <td>1.046790</td>\n",
              "      <td>0.487112</td>\n",
              "      <td>1.008364</td>\n",
              "      <td>1.005883</td>\n",
              "      <td>1.195057</td>\n",
              "      <td>0.505672</td>\n",
              "      <td>1.008151</td>\n",
              "      <td>1.005563</td>\n",
              "      <td>1.397913</td>\n",
              "      <td>0.669433</td>\n",
              "      <td>0.378087</td>\n",
              "      <td>0.164444</td>\n",
              "      <td>0.398453</td>\n",
              "      <td>0.524886</td>\n",
              "      <td>0.364497</td>\n",
              "      <td>0.313074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>-2.430000</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.139000</td>\n",
              "      <td>-2.970000</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>-2.910000</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264000</td>\n",
              "      <td>-2.730000</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365000</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>-1.740000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.107000</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>0.092200</td>\n",
              "      <td>0.157000</td>\n",
              "      <td>0.048100</td>\n",
              "      <td>0.303000</td>\n",
              "      <td>0.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591000</td>\n",
              "      <td>-0.737000</td>\n",
              "      <td>-0.870000</td>\n",
              "      <td>0.577000</td>\n",
              "      <td>-0.873000</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>-0.689000</td>\n",
              "      <td>-0.868000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>-0.693000</td>\n",
              "      <td>-0.871000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.651000</td>\n",
              "      <td>-0.697000</td>\n",
              "      <td>-0.870000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.618000</td>\n",
              "      <td>-0.715000</td>\n",
              "      <td>-0.872000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791000</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>0.986000</td>\n",
              "      <td>0.768000</td>\n",
              "      <td>0.674000</td>\n",
              "      <td>0.819000</td>\n",
              "      <td>0.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.854000</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>0.002640</td>\n",
              "      <td>0.891000</td>\n",
              "      <td>-0.001910</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>-0.003000</td>\n",
              "      <td>-0.001050</td>\n",
              "      <td>1.090000</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.001990</td>\n",
              "      <td>-0.001310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.868000</td>\n",
              "      <td>-0.000461</td>\n",
              "      <td>-0.005810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.917000</td>\n",
              "      <td>0.873000</td>\n",
              "      <td>0.947000</td>\n",
              "      <td>0.872000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>1.290000</td>\n",
              "      <td>0.872000</td>\n",
              "      <td>1.170000</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>2.170000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>0.872000</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>1.220000</td>\n",
              "      <td>0.703000</td>\n",
              "      <td>0.873000</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>1.220000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.868000</td>\n",
              "      <td>3.100000</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>1.080000</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>1.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.710000</td>\n",
              "      <td>2.430000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>8.380000</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>2.170000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>2.910000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>8.510000</td>\n",
              "      <td>2.730000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>3.100000</td>\n",
              "      <td>22.300000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>5.920000</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>13.700000</td>\n",
              "      <td>8.430000</td>\n",
              "      <td>6.260000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-284ba932-f7a7-4058-a734-37e5bb57911d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-284ba932-f7a7-4058-a734-37e5bb57911d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-284ba932-f7a7-4058-a734-37e5bb57911d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(\"shape:\", data.shape)\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUJUK8kiJPIW"
      },
      "source": [
        "### Process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2g5Jjr0X5pv"
      },
      "outputs": [],
      "source": [
        "engineered_parameters = [\"m jj\",  \"m jjj\", \"m lv\", \"m jlv\", \"m bb\", \"m wbb\", \"m wwbb\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZCr3GfIxCdA"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, 1:]\n",
        "y = data['Higgs boson']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "mean = tf.reduce_mean(X_train, axis=0)\n",
        "std = tf.math.reduce_std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1U-RZNRw4GQ"
      },
      "source": [
        "### Define the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag0fad4NrnuU"
      },
      "source": [
        "#### Stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rtDjPzzrQVp"
      },
      "outputs": [],
      "source": [
        "def fast_MLP(name = None, compile = True):\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=1024, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=512, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=256, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=128, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=64, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=32, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=16, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "  ], name)\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0005),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kg0MuKeruXj"
      },
      "outputs": [],
      "source": [
        "def deep_MLP(name = None, compile = True):\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=256, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=128, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=128, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=64, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=64, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=32, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=32, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=16, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "  ], name)\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0005),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAE_rPsVoL54"
      },
      "outputs": [],
      "source": [
        "def tanh_MLP(name = None, compile = True):\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=256, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=128, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=128, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=64, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=64, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=32, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=32, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=16, activation='tanh', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid', kernel_regularizer = keras.regularizers.L1(0.000001)),\n",
        "  ], name)\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.001),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWPiA4H0ryr9"
      },
      "outputs": [],
      "source": [
        "def MLP_ensemble(MLP_number, name = None, compile = True):\n",
        "  input = keras.Input(shape=(X_train.shape[1],))\n",
        "  models = [fast_MLP(compile = False)(input) for _ in range(MLP_number)]\n",
        "  output = keras.layers.average(models)\n",
        "  ensemble_model = keras.Model(inputs = input, outputs = output, name = name)\n",
        "  if(compile):\n",
        "    ensemble_model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0005),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return ensemble_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7PkEGHKWUhi"
      },
      "outputs": [],
      "source": [
        "def get_error_data(model, X, y):\n",
        "  predictions = model.predict(X, batch_size = 2048, verbose = 0) > 0.5\n",
        "  false_predictions = (predictions[:, 0] - y.to_numpy()) != 0\n",
        "  return X[false_predictions], y[false_predictions]\n",
        "\n",
        "def boosted_MLP(X_train, y_train, X_test, y_test, name = None):\n",
        "  X_first, X_second, y_first, y_second = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "\n",
        "  first = fast_MLP(compile = True)\n",
        "  print(\"First model\")\n",
        "  first.fit(\n",
        "    X_first,\n",
        "    y_first,\n",
        "    epochs = 50,\n",
        "    batch_size = 2048,\n",
        "    validation_data = (X_test, y_test),\n",
        "    use_multiprocessing = True\n",
        "  )\n",
        "\n",
        "  X_error, y_error = get_error_data(first, X_first, y_first)\n",
        "\n",
        "  print(\"Second model\")\n",
        "  second = lilit_1(compile = True)\n",
        "  second.fit(\n",
        "    pd.concat([X_error, X_second]),\n",
        "    pd.concat([y_error, y_second]),\n",
        "    epochs = 50,\n",
        "    batch_size = 2048,\n",
        "    validation_data = (X_test, y_test),\n",
        "    use_multiprocessing = True\n",
        "  )\n",
        "  \n",
        "  input = keras.Input(shape=(X.shape[1],))\n",
        "  models = [model(input) for model in [first, second]]\n",
        "  output = keras.layers.average(models)\n",
        "  ensemble_model = keras.Model(inputs = input, outputs = output, name = name)\n",
        "  if(compile):\n",
        "    ensemble_model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0005),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return ensemble_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzD7bAJbhcgJ"
      },
      "outputs": [],
      "source": [
        "def test_MLP(name = None, compiled = True):\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=8192, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00005)),\n",
        "    keras.layers.Dropout(0.30),\n",
        "    keras.layers.Dense(units=4096, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00003)),\n",
        "    keras.layers.Dropout(0.20),\n",
        "    keras.layers.Dense(units=2048, activation='relu', kernel_regularizer = keras.regularizers.L1(0.00002)),\n",
        "    keras.layers.Dropout(0.10),\n",
        "    keras.layers.Dense(units=1024, activation='relu', kernel_regularizer = keras.regularizers.L1(0.000005)),\n",
        "    keras.layers.Dropout(0.10),\n",
        "    keras.layers.Dense(units=512, activation='relu'),\n",
        "    keras.layers.Dropout(0.05),\n",
        "    keras.layers.Dense(units=256, activation='relu'),\n",
        "    keras.layers.Dropout(0.05),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "  ], name)\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0003),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494KiyF13YB8"
      },
      "source": [
        "#### Sam's copies of lilit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Z-zh7K3bKT"
      },
      "outputs": [],
      "source": [
        "def lilit_1(name = None, compile = True):\n",
        "  X_raw = X_train.iloc[:, 0:21]\n",
        "  X_high_level = X_train.iloc[:, 21:]\n",
        "\n",
        "  inputs_1 = keras.Input(shape=(X_raw.shape[1], ))\n",
        "  x_1 = keras.layers.Dense(1024, activation=\"relu\")(inputs_1)\n",
        "  x_1 = keras.layers.Dropout(0.4)(x_1)\n",
        "  x_1 = keras.layers.Dense(720, activation = \"relu\")(x_1)\n",
        "  x_1 = keras.layers.Dropout(0.2)(x_1)\n",
        "  x_1 = keras.layers.Dense(512, activation = \"relu\")(x_1)\n",
        "  x_1 = keras.layers.Dropout(0.2)(x_1)\n",
        "  x_1 = keras.layers.Dense(72, activation = \"relu\")(x_1)\n",
        "  x_1 = keras.layers.Dropout(0.2)(x_1)\n",
        "  output_1 = keras.layers.Dense(16, activation = \"relu\")(x_1)\n",
        "\n",
        "  inputs_2 = keras.Input(shape=(X_high_level.shape[1], ))\n",
        "  x_2 = keras.layers.Dense(512, activation=\"relu\")(inputs_2)\n",
        "  x_2 = keras.layers.Dropout(0.4)(x_2)\n",
        "  x_2 = keras.layers.Dense(256, activation = \"relu\")(x_2)\n",
        "  x_2 = keras.layers.Dropout(0.2)(x_2)\n",
        "  x_2 = keras.layers.Dense(128, activation = \"relu\")(x_2)\n",
        "  x_2 = keras.layers.Dropout(0.2)(x_2)\n",
        "  output_2 = keras.layers.Dense(8, activation = \"relu\")(x_2)\n",
        "\n",
        "  merged = keras.layers.concatenate([output_1, output_2])\n",
        "  merged = keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.00002))(merged)\n",
        "  merged = keras.layers.Dropout(0.25)(merged)\n",
        "  merged = keras.layers.Dense(1, activation=\"sigmoid\")(merged)\n",
        "\n",
        "  model = keras.Model(inputs=[inputs_1, inputs_2], outputs=merged, name = name)\n",
        "\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=keras.optimizers.Adam(0.0005),\n",
        "      metrics='accuracy',\n",
        "    )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7d8Ma704Tzx"
      },
      "outputs": [],
      "source": [
        "def lilit_2(name = None, compile = True):\n",
        "  inputs_a = keras.layers.Input(shape=(X_train.shape[1],))\n",
        "  x_a = keras.layers.Dense(1024, activation='relu')(inputs_a)\n",
        "  x_a = keras.layers.Dropout(0.25)(x_a)\n",
        "  x_a = keras.layers.Dense(256, activation='relu')(x_a)\n",
        "  x_a = keras.layers.Dropout(0.2)(x_a)\n",
        "  x_a = keras.layers.Dense(16, activation='relu')(x_a)\n",
        "  x_a = keras.layers.Dropout(0.2)(x_a)\n",
        "  att = keras.layers.Dense(1, activation='softmax')(x_a)\n",
        "\n",
        "  att_out = keras.layers.Multiply()([x_a, att])\n",
        "\n",
        "  att_out = keras.layers.Dense(512, activation='relu')(att_out)\n",
        "  att_out = keras.layers.Dropout(0.2)(att_out)\n",
        "  att_out = keras.layers.Dense(64, activation='relu')(att_out)\n",
        "  att_out = keras.layers.Dropout(0.2)(att_out)\n",
        "  outputs_a = keras.layers.Dense(1, activation='sigmoid')(att_out)\n",
        "\n",
        "  att_model = keras.models.Model(inputs=inputs_a, outputs=outputs_a)\n",
        "  att_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return att_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pseudo_final(name = None, compile = True):\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(units=8192, activation='relu', kernel_regularizer = keras.regularizers.L1(0.0002)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(units=4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(units=1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.20),\n",
        "    keras.layers.Dense(units=512, activation='relu'),\n",
        "    keras.layers.Dropout(0.15),\n",
        "    keras.layers.Dense(units=64),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "  ], name)\n",
        "  if(compile):\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(0.0005),\n",
        "        metrics='accuracy',\n",
        "    )\n",
        "  return model"
      ],
      "metadata": {
        "id": "pPM5bohnFUWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ts2Y9T3g1DF"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLb6gRgTR-bU"
      },
      "outputs": [],
      "source": [
        "def functional_model():\n",
        "  input_layer = keras.Input(shape=(X_train.shape[1] - 1,), name='input_layer')\n",
        "  Layer_1 = keras.layers.Dense(10, activation=\"relu\",name='Layer_1')(input_layer)\n",
        "  Layer_2 = keras.layers.Dense(10, activation=\"relu\",name='Layer_2')(Layer_1)\n",
        "  output_layer= keras.layers.Dense(1, activation=\"sigmoid\",name='output_layer')(Layer_2)\n",
        "\n",
        "  model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=keras.optimizers.Adam(0.0005),\n",
        "      metrics='accuracy',\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9HawapcUTs"
      },
      "source": [
        "### Train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7xrBEhugvNC"
      },
      "outputs": [],
      "source": [
        "models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM0QgA8WmeBa"
      },
      "outputs": [],
      "source": [
        "def train_model(model, parameters = None):\n",
        "  model.fit(\n",
        "    X_train if parameters == None else X_train[parameters],\n",
        "    y_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 2048,\n",
        "    validation_data = (X_test if parameters == None else X_test[parameters], y_test),\n",
        "    use_multiprocessing = True,\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "        filepath=f'/content/drive/My Drive/Higgs_Boson_Project/Saved_models/{model.name}.h5',\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "        )\n",
        "      ]\n",
        "  )\n",
        "  models[model.name] = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwABh1qxdJM5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_model(pseudo_final('model2'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbMP_icgJD6_"
      },
      "source": [
        "### Evaluate a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BSiIHITKXFX"
      },
      "outputs": [],
      "source": [
        "separator = '----------------------------------------------------------'\n",
        "def show_confusion_matrix(model, X, y, proportions = False):\n",
        "  predictions = (model.predict(X, batch_size = 2048, verbose = 0) > 0.5).astype(int)\n",
        "  print(f\"{model.name}'s confusion matrix\")\n",
        "  print(pd.DataFrame(\n",
        "    tf.math.confusion_matrix(predictions, y) / (y.size if proportions else 1),\n",
        "    columns = ['Not Higgs', 'Higgs'],\n",
        "    index = ['Predicted not Higgs', 'Predicted Higgs']\n",
        "  ))\n",
        "  print(separator)\n",
        "\n",
        "def show_prediction_similarity(model1, model2, X1, X2):\n",
        "  predictions_1 = (model1.predict(X1, batch_size = 2048, verbose = 0) > 0.5).astype(int)\n",
        "  predictions_2 = (model2.predict(X2, batch_size = 2048, verbose = 0) > 0.5).astype(int)\n",
        "  print(pd.DataFrame(\n",
        "    tf.math.confusion_matrix(predictions_1.T[0], predictions_2.T[0]),\n",
        "    index = [f'Not Higgs {model1.name}', f'Higgs {model1.name}'],\n",
        "    columns = [f'Not Higgs {model2.name}', f'Higgs {model2.name}']\n",
        "  ))\n",
        "  print(separator)\n",
        "\n",
        "def get_error_similarity(model1, model2, X1, X2, y):\n",
        "  predictions_1 = (model1.predict(X1, batch_size = 2048, verbose = 0) > 0.5)\n",
        "  predictions_2 = (model2.predict(X2, batch_size = 2048, verbose = 0) > 0.5)\n",
        "\n",
        "  true_predictions_1 = (predictions_1[:, 0] - y.to_numpy()) == 0\n",
        "  true_predictions_2 = (predictions_2[:, 0] - y.to_numpy()) == 0\n",
        "\n",
        "  return tf.math.confusion_matrix(true_predictions_1, true_predictions_2)\n",
        "\n",
        "def show_error_similarity(model1, model2, X1, X2, y):\n",
        "  print(pd.DataFrame(\n",
        "    get_error_similarity(model1, model2, X1, X2, y),\n",
        "    index = ['Mistakes model 1', 'Accuracies model 1'],\n",
        "    columns = ['Mistakes model 2', 'Accuracies model 2']\n",
        "  ))\n",
        "  print(separator)\n",
        "\n",
        "def get_similar_error_proportion(model1, model2, X1, X2, y):\n",
        "  matrix = get_error_similarity(model1, model2, X1, X2, y)\n",
        "  return matrix[0, 0] / (matrix[0, 0] + matrix[0, 1] + matrix[1, 0])\n",
        "\n",
        "def compare(model1, model2, X1, X2, y):\n",
        "  show_confusion_matrix(model1, X1, y)\n",
        "  show_confusion_matrix(model2, X2, y)\n",
        "  show_prediction_similarity(model1, model2, X1, X2)\n",
        "  show_error_similarity(model1, model2, X1, X2, y)\n",
        "  get_similar_error_proportion(model1, model2, X1, X2, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeWdCUI4dGN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a071927-73a3-4138-e9db-236eb2f839ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1's confusion matrix\n",
            "                     Not Higgs    Higgs\n",
            "Predicted not Higgs    41079.0  14374.0\n",
            "Predicted Higgs        15122.0  49425.0\n",
            "----------------------------------------------------------\n",
            "test4's confusion matrix\n",
            "                     Not Higgs    Higgs\n",
            "Predicted not Higgs    41202.0  14379.0\n",
            "Predicted Higgs        14999.0  49420.0\n",
            "----------------------------------------------------------\n",
            "                  Not Higgs test4  Higgs test4\n",
            "Not Higgs model1            49761         5692\n",
            "Higgs model1                 5820        58727\n",
            "----------------------------------------------------------\n",
            "                    Mistakes model 2  Accuracies model 2\n",
            "Mistakes model 1               23681                5815\n",
            "Accuracies model 1              5697               84807\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "compare(models['model1'], models['test4'], X_test, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otvbgvo_Ic5J",
        "outputId": "1f045366-7a9d-4dbb-b563-ac126b2b2ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 0.4367 - accuracy: 0.8104\n",
            "testing accuracy\n",
            "59/59 [==============================] - 3s 46ms/step - loss: 0.5250 - accuracy: 0.7552\n",
            "test4's confusion matrix\n",
            "                     Not Higgs    Higgs\n",
            "Predicted not Higgs    41202.0  14379.0\n",
            "Predicted Higgs        14999.0  49420.0\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "name = 'test4'\n",
        "def evaluate(model, X, y):\n",
        "  model.evaluate(X, y, batch_size = 2048)\n",
        "\n",
        "print('training accuracy')\n",
        "evaluate(models[name], X_train, y_train)\n",
        "print('testing accuracy')\n",
        "evaluate(models[name], X_test, y_test)\n",
        "show_confusion_matrix(models[name], X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYgPfcDno_lb"
      },
      "outputs": [],
      "source": [
        "# Show a model\n",
        "# models[name].summary(expand_nested = False, show_trainable = True)\n",
        "keras.utils.plot_model(models[name], f\"{name}.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM2sY8FXqLeC"
      },
      "source": [
        "### Save a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0EwZ3PUyWo"
      },
      "outputs": [],
      "source": [
        "# Make sure that no other model has the same name, to not override another one\n",
        "model_name = \"test3\"\n",
        "models[model_name].save(f\"/content/drive/My Drive/Higgs_Boson_Project/Saved_models/{model_name}.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLefwoL9LiLd"
      },
      "source": [
        "### Load a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwxF2ijlDdL3"
      },
      "outputs": [],
      "source": [
        "loaded_model_name = \"model-76-27\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abY_ZpV_IO6f"
      },
      "outputs": [],
      "source": [
        "loaded = keras.models.load_model(f\"/content/drive/My Drive/Higgs_Boson_Project/Saved_models/{loaded_model_name}.h5\")\n",
        "loaded.evaluate(X, y)\n",
        "loaded.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional models:"
      ],
      "metadata": {
        "id": "qqOpNRrxIaA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to prune\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.4, 0)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "model_for_pruning.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_for_pruning.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=2048, \n",
        "    epochs=4, \n",
        "    validation_data = (X_test, y_test),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "arkCDhM2GcFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model\n",
        "X_raw = X_train.iloc[:, 0:21]\n",
        "X_high_level = X_train.iloc[:, 21:]\n",
        "\n",
        "X_test_raw = X_test.iloc[:, 0:21]\n",
        "X_test_high_level = X_test.iloc[:, 21:]\n",
        "\n",
        "inputs_raw = keras.Input(shape=(X_raw.shape[1], ))\n",
        "x_raw = keras.layers.Dense(1024, activation=\"relu\")(inputs_raw)\n",
        "x_raw = keras.layers.Dropout(0.4)(x_raw)\n",
        "x_raw = keras.layers.Dense(512, activation = \"relu\")(x_raw)\n",
        "x_raw = keras.layers.Dropout(0.2)(x_raw)\n",
        "x_raw = keras.layers.Dense(256, activation = \"relu\")(x_raw)\n",
        "x_raw = keras.layers.Dropout(0.2)(x_raw)\n",
        "x_raw = keras.layers.Dense(128, activation = \"relu\")(x_raw)\n",
        "x_raw = keras.layers.Dropout(0.2)(x_raw)\n",
        "x_raw = keras.layers.Dense(64, activation = \"relu\")(x_raw)\n",
        "output_raw = keras.layers.Dense(32, activation = \"relu\")(x_raw)\n",
        "\n",
        "inputs_high_level = keras.Input(shape=(X_high_level.shape[1], ))\n",
        "x_high_level = keras.layers.Dense(420, activation=\"relu\")(inputs_high_level)\n",
        "x_high_level = keras.layers.Dropout(0.4)(x_high_level)\n",
        "x_high_level = keras.layers.Dense(128, activation = \"relu\")(x_high_level)\n",
        "x_high_level = keras.layers.Dropout(0.2)(x_high_level)\n",
        "x_high_level = keras.layers.Dense(64, activation = \"relu\")(x_high_level)\n",
        "x_high_level = keras.layers.Dropout(0.2)(x_high_level)\n",
        "output_high_level = keras.layers.Dense(16, activation = \"relu\")(x_high_level)\n",
        "\n",
        "merged = keras.layers.concatenate([output_raw, output_high_level])\n",
        "merged = keras.layers.Dense(6000, activation=\"relu\")(merged)\n",
        "merged = keras.layers.Dropout(0.4)(merged)\n",
        "merged = keras.layers.Dense(4096, activation=\"relu\")(merged)\n",
        "merged = keras.layers.Dropout(0.25)(merged)\n",
        "merged = keras.layers.Dense(1024, activation=\"relu\")(merged)\n",
        "merged = keras.layers.Dropout(0.2)(merged)\n",
        "merged = keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.0002))(merged)\n",
        "merged = keras.layers.Dropout(0.2)(merged)\n",
        "merged = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.0002))(merged)\n",
        "merged = keras.layers.Dropout(0.2)(merged)\n",
        "merged = keras.layers.Dense(1, activation=\"sigmoid\")(merged)\n",
        "\n",
        "final_model = keras.Model(inputs=[inputs_raw, inputs_high_level], outputs=merged)"
      ],
      "metadata": {
        "id": "M73sAOZeG_bz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "K34Wpd8IXew2",
        "pAJog-WzX8rY",
        "iUJUK8kiJPIW",
        "1Ts2Y9T3g1DF"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}